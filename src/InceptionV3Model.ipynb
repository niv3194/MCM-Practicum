{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InceptionV3Model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8M3mcT96GSi",
        "colab_type": "text"
      },
      "source": [
        "**Inception V3 pretrained model for recognition of events from images**\n",
        "\n",
        "This code is adapted from \"Flower17\" classification project available at : https://github.com/bouwkast/Flower-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxyXUE6_8c4-",
        "colab_type": "code",
        "outputId": "23b14b28-cc0b-498c-a2fb-614da409ffd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.models import Model\n",
        "from keras.layers import Dense, GlobalAveragePooling2D\n",
        "\n",
        "\n",
        "# Create the base pre-trained model\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h1xwTy98gdF",
        "colab_type": "code",
        "outputId": "5fe9f120-7099-4a20-efa0-30a0eababe20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        }
      },
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
        "batch_size = 32  # batch size is chosen to help keep GPU memory usage low\n",
        "dim = 299  # InceptionV3 is trained on 299x299 images"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0809 10:35:09.839377 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0809 10:35:09.892354 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0809 10:35:09.900448 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0809 10:35:09.938286 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0809 10:35:09.939858 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "W0809 10:35:12.800335 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
            "\n",
            "W0809 10:35:13.070198 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0809 10:35:13.970528 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 7s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FsKvyhG8kmN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_training_img = 1470  # number of training images for dataset\n",
        "num_val_img = 350  # number of validation images for dataset\n",
        "# Add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# Add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzaBSXJu8wvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select number of events to train on\n",
        "predictions = Dense(7, activation='softmax')(x)\n",
        "# predictions = Dense(17, activation='softmax')(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuYMji408y3t",
        "colab_type": "code",
        "outputId": "32f5e4cc-6ce3-4828-d8fa-297aa3a4b0d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# This is the model we will train\n",
        "model = Model(input=base_model.input, output=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74HfDmfW81ev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# First: train only the top layers (which were randomly initialized)\n",
        "# i.e. freeze all convolutional InceptionV3 layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQU7VG7-84Yx",
        "colab_type": "code",
        "outputId": "5b3fb520-ff13-4615-88d9-8ee0162b3a29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Compile the model (should be done *after* setting layers to non-trainable)\n",
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 10:36:40.964383 140060236105600 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfWf_aeu8614",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessor for the training training data\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,  # regularize RGB color values to floats between 0.0 to 1.0\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='constant')  # in case resizing needs to create new image - fill it in with black\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVn07bWh89Oi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# preprocessor for the testing data\n",
        "# only rescaling for regularization\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhdmucSp9MKd",
        "colab_type": "code",
        "outputId": "626f1c09-0a00-41ae-c19a-053d2de31caf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount('/content/drive/')\n",
        "os.chdir('/content/drive/My Drive/widerdata/images')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ow53tVrB9OXK",
        "colab_type": "code",
        "outputId": "36ea0fb2-e1a8-4788-c7c4-97decf5e24a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generator for creating batch_size of training images with all transformations applied\n",
        "# leaves us with more images than we start with\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/widerdata/images',  # this is the target directory\n",
        "    target_size=(dim, dim),  # all images will be resized to dim * dim\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1470 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8GevQ8M9ZNH",
        "colab_type": "code",
        "outputId": "59369b70-9a5f-4224-8307-b727cdf0ea5c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# generator for creating batch_size of validation images with only regularization and resizing\n",
        "# leaves us with the same amount of images that we start with\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    '/content/drive/My Drive/Validation/images',\n",
        "    target_size=(dim, dim),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 350 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEUuKhVH9btD",
        "colab_type": "code",
        "outputId": "0897a35f-d3de-4938-c5aa-412bf306a529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(validation_generator.class_indices)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'0 Parade': 0, '1 Handshaking': 1, '2 Demonstration': 2, '3 Riot': 3, '4 Cheering': 4, '5 Shoppers': 5, '6 Soccer': 6}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2uyWtFY9fLR",
        "colab_type": "code",
        "outputId": "87690799-660b-44fe-a215-17946f72e71d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        }
      },
      "source": [
        "# all InceptionV3 layers are frozen, we train our added layers, where the weights were randomly initialized\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=num_training_img // batch_size,  # steps =  num_images // batch_size = total num of complete passes\n",
        "    epochs=10,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=num_val_img // batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0809 10:39:21.234809 140060236105600 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "45/45 [==============================] - 945s 21s/step - loss: 3.4793 - acc: 0.3049 - val_loss: 2.2891 - val_acc: 0.3125\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 34s 763ms/step - loss: 1.6306 - acc: 0.4337 - val_loss: 1.0340 - val_acc: 0.6258\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 18s 400ms/step - loss: 1.4280 - acc: 0.4894 - val_loss: 1.3066 - val_acc: 0.6038\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 18s 399ms/step - loss: 1.2473 - acc: 0.5752 - val_loss: 1.5548 - val_acc: 0.5252\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 18s 398ms/step - loss: 1.1589 - acc: 0.5832 - val_loss: 1.4947 - val_acc: 0.5063\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 18s 397ms/step - loss: 1.1204 - acc: 0.5919 - val_loss: 1.1042 - val_acc: 0.6352\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 18s 398ms/step - loss: 1.0403 - acc: 0.6194 - val_loss: 1.5027 - val_acc: 0.5566\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 18s 397ms/step - loss: 0.9966 - acc: 0.6605 - val_loss: 1.8606 - val_acc: 0.4717\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 18s 399ms/step - loss: 0.9348 - acc: 0.6703 - val_loss: 1.2526 - val_acc: 0.6352\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 18s 399ms/step - loss: 0.8938 - acc: 0.6787 - val_loss: 1.2977 - val_acc: 0.6006\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61b4983198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZkj_tlG9h7U",
        "colab_type": "code",
        "outputId": "edeae94c-970f-4024-e9e5-98f1750264e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# At this point, the top layers are well trained and we can start fine-tuning\n",
        "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
        "# and train the remaining top layers.\n",
        "\n",
        "# Let's visualize layer names and layer indices to see how many layers we should freeze:\n",
        "for i, layer in enumerate(base_model.layers):\n",
        "    print(i, layer.name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 input_1\n",
            "1 conv2d_1\n",
            "2 batch_normalization_1\n",
            "3 activation_1\n",
            "4 conv2d_2\n",
            "5 batch_normalization_2\n",
            "6 activation_2\n",
            "7 conv2d_3\n",
            "8 batch_normalization_3\n",
            "9 activation_3\n",
            "10 max_pooling2d_1\n",
            "11 conv2d_4\n",
            "12 batch_normalization_4\n",
            "13 activation_4\n",
            "14 conv2d_5\n",
            "15 batch_normalization_5\n",
            "16 activation_5\n",
            "17 max_pooling2d_2\n",
            "18 conv2d_9\n",
            "19 batch_normalization_9\n",
            "20 activation_9\n",
            "21 conv2d_7\n",
            "22 conv2d_10\n",
            "23 batch_normalization_7\n",
            "24 batch_normalization_10\n",
            "25 activation_7\n",
            "26 activation_10\n",
            "27 average_pooling2d_1\n",
            "28 conv2d_6\n",
            "29 conv2d_8\n",
            "30 conv2d_11\n",
            "31 conv2d_12\n",
            "32 batch_normalization_6\n",
            "33 batch_normalization_8\n",
            "34 batch_normalization_11\n",
            "35 batch_normalization_12\n",
            "36 activation_6\n",
            "37 activation_8\n",
            "38 activation_11\n",
            "39 activation_12\n",
            "40 mixed0\n",
            "41 conv2d_16\n",
            "42 batch_normalization_16\n",
            "43 activation_16\n",
            "44 conv2d_14\n",
            "45 conv2d_17\n",
            "46 batch_normalization_14\n",
            "47 batch_normalization_17\n",
            "48 activation_14\n",
            "49 activation_17\n",
            "50 average_pooling2d_2\n",
            "51 conv2d_13\n",
            "52 conv2d_15\n",
            "53 conv2d_18\n",
            "54 conv2d_19\n",
            "55 batch_normalization_13\n",
            "56 batch_normalization_15\n",
            "57 batch_normalization_18\n",
            "58 batch_normalization_19\n",
            "59 activation_13\n",
            "60 activation_15\n",
            "61 activation_18\n",
            "62 activation_19\n",
            "63 mixed1\n",
            "64 conv2d_23\n",
            "65 batch_normalization_23\n",
            "66 activation_23\n",
            "67 conv2d_21\n",
            "68 conv2d_24\n",
            "69 batch_normalization_21\n",
            "70 batch_normalization_24\n",
            "71 activation_21\n",
            "72 activation_24\n",
            "73 average_pooling2d_3\n",
            "74 conv2d_20\n",
            "75 conv2d_22\n",
            "76 conv2d_25\n",
            "77 conv2d_26\n",
            "78 batch_normalization_20\n",
            "79 batch_normalization_22\n",
            "80 batch_normalization_25\n",
            "81 batch_normalization_26\n",
            "82 activation_20\n",
            "83 activation_22\n",
            "84 activation_25\n",
            "85 activation_26\n",
            "86 mixed2\n",
            "87 conv2d_28\n",
            "88 batch_normalization_28\n",
            "89 activation_28\n",
            "90 conv2d_29\n",
            "91 batch_normalization_29\n",
            "92 activation_29\n",
            "93 conv2d_27\n",
            "94 conv2d_30\n",
            "95 batch_normalization_27\n",
            "96 batch_normalization_30\n",
            "97 activation_27\n",
            "98 activation_30\n",
            "99 max_pooling2d_3\n",
            "100 mixed3\n",
            "101 conv2d_35\n",
            "102 batch_normalization_35\n",
            "103 activation_35\n",
            "104 conv2d_36\n",
            "105 batch_normalization_36\n",
            "106 activation_36\n",
            "107 conv2d_32\n",
            "108 conv2d_37\n",
            "109 batch_normalization_32\n",
            "110 batch_normalization_37\n",
            "111 activation_32\n",
            "112 activation_37\n",
            "113 conv2d_33\n",
            "114 conv2d_38\n",
            "115 batch_normalization_33\n",
            "116 batch_normalization_38\n",
            "117 activation_33\n",
            "118 activation_38\n",
            "119 average_pooling2d_4\n",
            "120 conv2d_31\n",
            "121 conv2d_34\n",
            "122 conv2d_39\n",
            "123 conv2d_40\n",
            "124 batch_normalization_31\n",
            "125 batch_normalization_34\n",
            "126 batch_normalization_39\n",
            "127 batch_normalization_40\n",
            "128 activation_31\n",
            "129 activation_34\n",
            "130 activation_39\n",
            "131 activation_40\n",
            "132 mixed4\n",
            "133 conv2d_45\n",
            "134 batch_normalization_45\n",
            "135 activation_45\n",
            "136 conv2d_46\n",
            "137 batch_normalization_46\n",
            "138 activation_46\n",
            "139 conv2d_42\n",
            "140 conv2d_47\n",
            "141 batch_normalization_42\n",
            "142 batch_normalization_47\n",
            "143 activation_42\n",
            "144 activation_47\n",
            "145 conv2d_43\n",
            "146 conv2d_48\n",
            "147 batch_normalization_43\n",
            "148 batch_normalization_48\n",
            "149 activation_43\n",
            "150 activation_48\n",
            "151 average_pooling2d_5\n",
            "152 conv2d_41\n",
            "153 conv2d_44\n",
            "154 conv2d_49\n",
            "155 conv2d_50\n",
            "156 batch_normalization_41\n",
            "157 batch_normalization_44\n",
            "158 batch_normalization_49\n",
            "159 batch_normalization_50\n",
            "160 activation_41\n",
            "161 activation_44\n",
            "162 activation_49\n",
            "163 activation_50\n",
            "164 mixed5\n",
            "165 conv2d_55\n",
            "166 batch_normalization_55\n",
            "167 activation_55\n",
            "168 conv2d_56\n",
            "169 batch_normalization_56\n",
            "170 activation_56\n",
            "171 conv2d_52\n",
            "172 conv2d_57\n",
            "173 batch_normalization_52\n",
            "174 batch_normalization_57\n",
            "175 activation_52\n",
            "176 activation_57\n",
            "177 conv2d_53\n",
            "178 conv2d_58\n",
            "179 batch_normalization_53\n",
            "180 batch_normalization_58\n",
            "181 activation_53\n",
            "182 activation_58\n",
            "183 average_pooling2d_6\n",
            "184 conv2d_51\n",
            "185 conv2d_54\n",
            "186 conv2d_59\n",
            "187 conv2d_60\n",
            "188 batch_normalization_51\n",
            "189 batch_normalization_54\n",
            "190 batch_normalization_59\n",
            "191 batch_normalization_60\n",
            "192 activation_51\n",
            "193 activation_54\n",
            "194 activation_59\n",
            "195 activation_60\n",
            "196 mixed6\n",
            "197 conv2d_65\n",
            "198 batch_normalization_65\n",
            "199 activation_65\n",
            "200 conv2d_66\n",
            "201 batch_normalization_66\n",
            "202 activation_66\n",
            "203 conv2d_62\n",
            "204 conv2d_67\n",
            "205 batch_normalization_62\n",
            "206 batch_normalization_67\n",
            "207 activation_62\n",
            "208 activation_67\n",
            "209 conv2d_63\n",
            "210 conv2d_68\n",
            "211 batch_normalization_63\n",
            "212 batch_normalization_68\n",
            "213 activation_63\n",
            "214 activation_68\n",
            "215 average_pooling2d_7\n",
            "216 conv2d_61\n",
            "217 conv2d_64\n",
            "218 conv2d_69\n",
            "219 conv2d_70\n",
            "220 batch_normalization_61\n",
            "221 batch_normalization_64\n",
            "222 batch_normalization_69\n",
            "223 batch_normalization_70\n",
            "224 activation_61\n",
            "225 activation_64\n",
            "226 activation_69\n",
            "227 activation_70\n",
            "228 mixed7\n",
            "229 conv2d_73\n",
            "230 batch_normalization_73\n",
            "231 activation_73\n",
            "232 conv2d_74\n",
            "233 batch_normalization_74\n",
            "234 activation_74\n",
            "235 conv2d_71\n",
            "236 conv2d_75\n",
            "237 batch_normalization_71\n",
            "238 batch_normalization_75\n",
            "239 activation_71\n",
            "240 activation_75\n",
            "241 conv2d_72\n",
            "242 conv2d_76\n",
            "243 batch_normalization_72\n",
            "244 batch_normalization_76\n",
            "245 activation_72\n",
            "246 activation_76\n",
            "247 max_pooling2d_4\n",
            "248 mixed8\n",
            "249 conv2d_81\n",
            "250 batch_normalization_81\n",
            "251 activation_81\n",
            "252 conv2d_78\n",
            "253 conv2d_82\n",
            "254 batch_normalization_78\n",
            "255 batch_normalization_82\n",
            "256 activation_78\n",
            "257 activation_82\n",
            "258 conv2d_79\n",
            "259 conv2d_80\n",
            "260 conv2d_83\n",
            "261 conv2d_84\n",
            "262 average_pooling2d_8\n",
            "263 conv2d_77\n",
            "264 batch_normalization_79\n",
            "265 batch_normalization_80\n",
            "266 batch_normalization_83\n",
            "267 batch_normalization_84\n",
            "268 conv2d_85\n",
            "269 batch_normalization_77\n",
            "270 activation_79\n",
            "271 activation_80\n",
            "272 activation_83\n",
            "273 activation_84\n",
            "274 batch_normalization_85\n",
            "275 activation_77\n",
            "276 mixed9_0\n",
            "277 concatenate_1\n",
            "278 activation_85\n",
            "279 mixed9\n",
            "280 conv2d_90\n",
            "281 batch_normalization_90\n",
            "282 activation_90\n",
            "283 conv2d_87\n",
            "284 conv2d_91\n",
            "285 batch_normalization_87\n",
            "286 batch_normalization_91\n",
            "287 activation_87\n",
            "288 activation_91\n",
            "289 conv2d_88\n",
            "290 conv2d_89\n",
            "291 conv2d_92\n",
            "292 conv2d_93\n",
            "293 average_pooling2d_9\n",
            "294 conv2d_86\n",
            "295 batch_normalization_88\n",
            "296 batch_normalization_89\n",
            "297 batch_normalization_92\n",
            "298 batch_normalization_93\n",
            "299 conv2d_94\n",
            "300 batch_normalization_86\n",
            "301 activation_88\n",
            "302 activation_89\n",
            "303 activation_92\n",
            "304 activation_93\n",
            "305 batch_normalization_94\n",
            "306 activation_86\n",
            "307 mixed9_1\n",
            "308 concatenate_2\n",
            "309 activation_94\n",
            "310 mixed10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCuxr56OFoVo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 172 layers and unfreeze the rest. This prevents overfitting.\n",
        "for layer in model.layers[:172]:\n",
        "    layer.trainable = False\n",
        "for layer in model.layers[172:]:\n",
        "    layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEw_gmJUFrAF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We need to recompile the model for these modifications to take effect\n",
        "# We use SGD with a low learning rate\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1EVACtJFs5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E95MVkCAFvFH",
        "colab_type": "code",
        "outputId": "81f5274d-34c7-4879-aaec-5544294e6b51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train our model while back propagating through our layers and the top two blocks of the InceptionV3 architecture\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    steps_per_epoch=num_training_img // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=num_val_img // batch_size,\n",
        "    callbacks=[EarlyStopping(patience=50), ModelCheckpoint('7_modelInceptionV31.h5', verbose=1, save_best_only=True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "45/45 [==============================] - 41s 906ms/step - loss: 0.6757 - acc: 0.7567 - val_loss: 0.9456 - val_acc: 0.6572\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.94556, saving model to 7_modelInceptionV31.h5\n",
            "Epoch 2/100\n",
            "45/45 [==============================] - 30s 657ms/step - loss: 0.5632 - acc: 0.8118 - val_loss: 0.9487 - val_acc: 0.6687\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.94556\n",
            "Epoch 3/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.4878 - acc: 0.8475 - val_loss: 0.8705 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.94556 to 0.87050, saving model to 7_modelInceptionV31.h5\n",
            "Epoch 4/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.4668 - acc: 0.8644 - val_loss: 0.9238 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.87050\n",
            "Epoch 5/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.4257 - acc: 0.8733 - val_loss: 0.9089 - val_acc: 0.6730\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.87050\n",
            "Epoch 6/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.4112 - acc: 0.8784 - val_loss: 0.9139 - val_acc: 0.6887\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.87050\n",
            "Epoch 7/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.3593 - acc: 0.9062 - val_loss: 1.0014 - val_acc: 0.6855\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.87050\n",
            "Epoch 8/100\n",
            "45/45 [==============================] - 29s 653ms/step - loss: 0.3542 - acc: 0.9068 - val_loss: 0.8277 - val_acc: 0.7327\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.87050 to 0.82775, saving model to 7_modelInceptionV31.h5\n",
            "Epoch 9/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.3162 - acc: 0.9213 - val_loss: 0.9147 - val_acc: 0.6730\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.82775\n",
            "Epoch 10/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.3018 - acc: 0.9283 - val_loss: 0.9616 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.82775\n",
            "Epoch 11/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.2816 - acc: 0.9351 - val_loss: 0.8819 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.82775\n",
            "Epoch 12/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.2586 - acc: 0.9492 - val_loss: 0.9109 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.82775\n",
            "Epoch 13/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.2595 - acc: 0.9477 - val_loss: 0.9174 - val_acc: 0.6844\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.82775\n",
            "Epoch 14/100\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.2184 - acc: 0.9645 - val_loss: 0.9455 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.82775\n",
            "Epoch 15/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.2448 - acc: 0.9408 - val_loss: 0.8910 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.82775\n",
            "Epoch 16/100\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.2000 - acc: 0.9618 - val_loss: 0.8886 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.82775\n",
            "Epoch 17/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.1912 - acc: 0.9728 - val_loss: 1.0108 - val_acc: 0.6730\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.82775\n",
            "Epoch 18/100\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.1731 - acc: 0.9728 - val_loss: 0.8531 - val_acc: 0.7264\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.82775\n",
            "Epoch 19/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.1684 - acc: 0.9728 - val_loss: 0.9175 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.82775\n",
            "Epoch 20/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.1667 - acc: 0.9756 - val_loss: 0.9540 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.82775\n",
            "Epoch 21/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.1628 - acc: 0.9743 - val_loss: 0.9410 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.82775\n",
            "Epoch 22/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.1486 - acc: 0.9797 - val_loss: 0.8742 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.82775\n",
            "Epoch 23/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.1498 - acc: 0.9798 - val_loss: 0.9561 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.82775\n",
            "Epoch 24/100\n",
            "45/45 [==============================] - 29s 653ms/step - loss: 0.1307 - acc: 0.9826 - val_loss: 0.9408 - val_acc: 0.6969\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.82775\n",
            "Epoch 25/100\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.1228 - acc: 0.9868 - val_loss: 0.9019 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.82775\n",
            "Epoch 26/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.1211 - acc: 0.9847 - val_loss: 0.9492 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.82775\n",
            "Epoch 27/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.1158 - acc: 0.9910 - val_loss: 0.9547 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.82775\n",
            "Epoch 28/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.1077 - acc: 0.9881 - val_loss: 0.9437 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.82775\n",
            "Epoch 29/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.1127 - acc: 0.9882 - val_loss: 0.9284 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.82775\n",
            "Epoch 30/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0914 - acc: 0.9931 - val_loss: 0.9809 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.82775\n",
            "Epoch 31/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0890 - acc: 0.9951 - val_loss: 0.8852 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.82775\n",
            "Epoch 32/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0915 - acc: 0.9924 - val_loss: 0.9327 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.82775\n",
            "Epoch 33/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0871 - acc: 0.9944 - val_loss: 1.0127 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.82775\n",
            "Epoch 34/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0802 - acc: 0.9937 - val_loss: 0.9342 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.82775\n",
            "Epoch 35/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0778 - acc: 0.9958 - val_loss: 0.9215 - val_acc: 0.7031\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.82775\n",
            "Epoch 36/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0711 - acc: 0.9965 - val_loss: 0.9744 - val_acc: 0.7107\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.82775\n",
            "Epoch 37/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0716 - acc: 0.9951 - val_loss: 0.9959 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.82775\n",
            "Epoch 38/100\n",
            "45/45 [==============================] - 29s 653ms/step - loss: 0.0747 - acc: 0.9937 - val_loss: 0.9563 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.82775\n",
            "Epoch 39/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.0642 - acc: 0.9958 - val_loss: 0.9781 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.82775\n",
            "Epoch 40/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0597 - acc: 0.9979 - val_loss: 0.8975 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.82775\n",
            "Epoch 41/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0678 - acc: 0.9951 - val_loss: 0.9657 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.82775\n",
            "Epoch 42/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0567 - acc: 1.0000 - val_loss: 1.0444 - val_acc: 0.7013\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.82775\n",
            "Epoch 43/100\n",
            "45/45 [==============================] - 29s 653ms/step - loss: 0.0556 - acc: 0.9986 - val_loss: 0.8813 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.82775\n",
            "Epoch 44/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0597 - acc: 0.9958 - val_loss: 1.0134 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.82775\n",
            "Epoch 45/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0623 - acc: 0.9931 - val_loss: 0.9814 - val_acc: 0.7075\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.82775\n",
            "Epoch 46/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0544 - acc: 0.9986 - val_loss: 0.9716 - val_acc: 0.7063\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.82775\n",
            "Epoch 47/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0592 - acc: 0.9965 - val_loss: 0.9816 - val_acc: 0.7264\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.82775\n",
            "Epoch 48/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.0499 - acc: 0.9938 - val_loss: 1.0140 - val_acc: 0.6887\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.82775\n",
            "Epoch 49/100\n",
            "45/45 [==============================] - 29s 649ms/step - loss: 0.0436 - acc: 0.9972 - val_loss: 0.8576 - val_acc: 0.7201\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.82775\n",
            "Epoch 50/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0426 - acc: 0.9993 - val_loss: 1.0520 - val_acc: 0.6950\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.82775\n",
            "Epoch 51/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0463 - acc: 0.9979 - val_loss: 1.0404 - val_acc: 0.6918\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.82775\n",
            "Epoch 52/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0391 - acc: 0.9986 - val_loss: 0.9042 - val_acc: 0.7390\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.82775\n",
            "Epoch 53/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0429 - acc: 0.9993 - val_loss: 1.0344 - val_acc: 0.6730\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.82775\n",
            "Epoch 54/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.0444 - acc: 0.9979 - val_loss: 0.9971 - val_acc: 0.7170\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.82775\n",
            "Epoch 55/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0403 - acc: 0.9993 - val_loss: 0.9688 - val_acc: 0.7138\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.82775\n",
            "Epoch 56/100\n",
            "45/45 [==============================] - 29s 652ms/step - loss: 0.0401 - acc: 0.9986 - val_loss: 0.9888 - val_acc: 0.7044\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.82775\n",
            "Epoch 57/100\n",
            "45/45 [==============================] - 29s 650ms/step - loss: 0.0369 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.7156\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.82775\n",
            "Epoch 58/100\n",
            "45/45 [==============================] - 29s 651ms/step - loss: 0.0377 - acc: 0.9986 - val_loss: 0.9906 - val_acc: 0.6981\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.82775\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f61b1ac6eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJL0L6Xx6UzV",
        "colab_type": "text"
      },
      "source": [
        "Testing process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCNnUMifFybv",
        "colab_type": "code",
        "outputId": "9ad8455b-6e8a-4175-9f56-0b7890fca0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_generator = ImageDataGenerator(rescale=1. / 255)\n",
        "test_data_generator = test_generator.flow_from_directory(\n",
        "    '/content/drive/My Drive/prediction2/images',\n",
        "    target_size=(dim, dim),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False)\n",
        "import numpy \n",
        "test_steps_per_epoch = numpy.math.ceil(test_data_generator.samples / test_data_generator.batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 140 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sQPUEHHO3MY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = model.predict_generator(test_data_generator, steps=test_steps_per_epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55vK6JFWO599",
        "colab_type": "code",
        "outputId": "0d9e9f9e-4e28-417c-9841-377e5ca2fc20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "predicted_classes = numpy.argmax(predictions, axis=1)\n",
        "print(len(predicted_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuQFeiMlPd4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_classes = test_data_generator.classes\n",
        "class_labels = list(test_data_generator.class_indices.keys())   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02cLZxSBPgBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = (train_generator.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_classes]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZEftiihPiE_",
        "colab_type": "code",
        "outputId": "2c8d2804-e34d-46b5-b60e-7014f022510f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "predicted_classes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 4, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 1, 1,\n",
              "       1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 2, 2,\n",
              "       2, 2, 5, 2, 2, 2, 2, 2, 2, 2, 1, 2, 2, 2, 3, 5, 3, 3, 3, 2, 3, 2,\n",
              "       3, 3, 3, 2, 3, 3, 2, 4, 3, 3, 3, 3, 3, 3, 4, 4, 1, 0, 4, 4, 4, 4,\n",
              "       4, 4, 0, 4, 4, 0, 2, 4, 1, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 2, 5, 5,\n",
              "       2, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 0, 6, 6, 6, 6,\n",
              "       6, 6, 6, 6, 6, 0, 6, 6])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AeIXNkkPleq",
        "colab_type": "code",
        "outputId": "6405e2e0-3b39-4966-a606-e7baffd0cbce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "class_labels"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0 Parade',\n",
              " '1 Handshaking',\n",
              " '2 Demonstration',\n",
              " '3 Riot',\n",
              " '4 Cheering',\n",
              " '5 Shoppers',\n",
              " '6 Soccer']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld0XaronPsnf",
        "colab_type": "code",
        "outputId": "605b5bfe-7290-48c8-cba3-06d0d1114485",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
        "print(report)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "       0 Parade       0.77      0.85      0.81        20\n",
            "  1 Handshaking       0.86      0.95      0.90        20\n",
            "2 Demonstration       0.62      0.75      0.68        20\n",
            "         3 Riot       0.88      0.75      0.81        20\n",
            "     4 Cheering       0.88      0.70      0.78        20\n",
            "     5 Shoppers       0.86      0.90      0.88        20\n",
            "       6 Soccer       1.00      0.90      0.95        20\n",
            "\n",
            "       accuracy                           0.83       140\n",
            "      macro avg       0.84      0.83      0.83       140\n",
            "   weighted avg       0.84      0.83      0.83       140\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOrxSHwNPvy5",
        "colab_type": "code",
        "outputId": "db569f09-a5a2-4a3d-e699-18b6c6a9f5d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# display the confusion matrix\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "print (\"[INFO] confusion matrix\")\n",
        "\n",
        "# get the list of training lables\n",
        "#labels = sorted(list(os.listdir(test_path)))\n",
        "\n",
        "# plot the confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "cm_df = pd.DataFrame(cm,\n",
        "                     index = ['parade','handshaking','demo','riot','cheering','shoppers','soccer'], \n",
        "                     columns = ['parade','handshaking','demo','riot','cheering','shoppers','soccer'])\n",
        "sns.heatmap(cm_df,\n",
        "            annot=True,\n",
        "            cmap=\"Set3\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] confusion matrix\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEyCAYAAADUa4YpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1Gg5_tHP0SL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}